LDX is an extension to python pandas. Instead of explicitly passing the parameters
to the pandas built-in methods (e.g groupby), it allows you use continuity variables (placeholders), which are determined during runtime.
The extension is especially useful for specifying the order of notebook's query operations and their type and parameters.
The continuity variables stores its value in order to reuse the same value in several places.
LDX currently supports only the following operations: filter, groupby, agg.

here are some basic examples how to convert tasks to LDX:

task: apply twice the same aggregation and same groupby
LDX:
       agg = df.groupby(<COL>).agg(<AGG>)
       same_agg = df.groupby(<COL>).agg(<AGG>)

task: apply two different aggregations, both grouped by the same column
LDX:
        agg1 = df.groupby(<COL>).agg(<AGG1>)
        agg2 = df.groupby(<COL>).agg(<AGG2>)

task: group by separately by two different columns, both aggregated with the same aggregation
LDX:
        groupby1 = df.groupby(<COL1>).agg(<AGG>)
        groupby2 = df.groupby(<COL2>).agg(<AGG>)

task: apply two completely different aggregations
LDX:
        agg1 = df.groupby(<COL1>).agg(<AGG1>)
        agg2 = df.groupby(<COL2>).agg(<AGG2>)

task: filter attribute ATT to some value
LDX:
      some_origin_airport = df[df['ATT'] == <VALUE>]

task: make sure at some point to filter attribute ATT to some value, there might be other operations before that.
LDX:
      do_some_operations()
      some_origin_airport = df[df['ATT'] == <VALUE>]

here are more complex examples how to convert tasks to LDX, given multiple domains:

task: find one game platform which has one different property compared to all the other platforms
dataset: epic_games
scheme: id, name, game_slug, price, release_date, platform, description, developer, publisher, genres
LDX:
        df = pd.read_csv("epic_games.tsv", delimiter="	")

        some_platform = df[df['platform'] == <VALUE>]
        other_platforms = df[df['platform'] != <VALUE>]

        some_platform_agg = some_platform.groupby(<COL>).agg(<AGG>)
        other_platforms_agg = other_platforms.groupby(<COL>).agg(<AGG>)
explanation: Split the games to two sets - one with some platform and one with the other platforms.
Then apply the same aggregation on both of them in order to compare them.

task: investigate what makes data scientists to earn above the 90th percentile salary (above $219,000, according to this dataset) and drill down to a specific reason
dataset: ds_salaries
scheme:	work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location
LDX:
       df = pd.read_csv("ds_salaries.tsv", delimiter="	")

       greater_than_219000 = df[df['salary_in_usd'] > 219000]

       properties1 = greater_than_219000.groupby(<COL1>).agg(<AGG1>)

       focus_of_col1 = greater_than_219000[greater_than_219000[<COL1>] == <VALUE1>]

       properties2 = focus_of_col1.groupby(<COL2>).agg(<AGG2>)

       focus_of_col2 = focus_of_col1[focus_of_col1[<COL2>] == <VALUE2>]
explanation: filter to salaries in usd greater than 219000.
Then, group according to some column and apply some aggregation in order to find some column that significantly influences the distribution of them.
After that filter on one of the values of the selected column from the previous step. Repeat it once again to drill down more.

task: compare some three different subsets of processors according to some properties
dataset: intel_processors
scheme:	Product, Status, Release Date, Cores, Threads, Lithography, Max. Turbo Freq, Base Freq, TDP, Cache
LDX:
        df = pd.read_csv("intel_processors.tsv", delimiter="	")

        first_product = df[df['Product'] == <VALUE1>]
        second_product = df[df['Product'] == <VALUE2>]
        third_product = df[df['Product'] == <VALUE3>]

        first_product_agg = first_product.groupby(<COL>).agg(<AGG>)
        second_product_agg = second_product.groupby(<COL>).agg(<AGG>)
        third_product_agg = third_product.groupby(<COL>).agg(<AGG>)
explanation: Split the processors to three sets, each one filtered to a different product.
Then apply the same aggregation on each of them in order to compare them.

task: show the average cost of some two different subsets of houses
dataset: houses
scheme: Area, BHK, Bathroom, Furnishing, Locality, Parking, Price, Status, Transaction, Type, Per_Sqft
LDX:
       df = pd.read_csv("houses.tsv", delimiter="	")

       first_subset = df[df[<COL1>] == <VALUE1>]
       first_subset_agg = first_subset.groupby(<AGG_COL1>).agg({'Price': 'mean'})

       second_subset = df[df[<COL2] == <VALUE2>]
       second_subset_agg = second_subset.groupby(<AGG_COL2>).agg({'Price': 'mean'})
explanation: filter the houses to some column and some of its values. Then, group the houses according to some column and calculate the average price. Do so one more time but on different subset of the houses.

task: show two properties of emojis published in 2022 compared to all the emojis
dataset: emojis
scheme: Hex, Rank, Emoji, Year, Category, Subcategory, Name
LDX:
       df = pd.read_csv("emojis.tsv", delimiter="	")

       emojis_properties_1 = df.groupby(<COL1>).agg(<AGG1>)
       emojis_properties_2 = df.groupby(<COL2>).agg(<AGG2>)

       2022_emojis = df[df['Year'] == 2022]
       2022_emojis_properties_1 = 2022_emojis.groupby(<COL1>).agg(<AGG1>)
       2022_emojis_properties_2 = 2022_emojis.groupby(<COL2>).agg(<AGG2>)
explanation: Apply two aggregations. Also filter the emojis to those published in the year 2022 and apply the same two aggregations in order to compare it to the previous step.

task: explore three different car models in different ways
dataset: cars
scheme: addref, city, assembly, body, make, model, year, engine, transmission, fuel
LDX:
       df = pd.read_csv("cars.tsv", delimiter="	")

       model1 = df[df['model'] == <VALUE1>]
       model2 = df[df['model'] == <VALUE2>]
       model3 = df[df['model'] == <VALUE3>]

       model1_properties = model1.groupby(<COL1>).agg(<AGG1>)
       model2_properties = model2.groupby(<COL2>).agg(<AGG2>)
       model3_properties = model3.groupby(<COL3>).agg(<AGG3>)
explanation: filter to three different models and for each one show some properties.

task: explore the data, make sure to address two interesting properties of the rapper Drake
dataset: spotify
scheme: Artist, Streams, Daily, As lead, Solo, As feature
LDX:
       df = pd.read_csv("spotify.tsv", delimiter="	")

       do_some_operations()

       drake_songs = df[df['Artist'] == 'Drake']

       drake_songs_properties_1 = drake_songs.groupby(<COL1>).agg(<AGG1>)
       drake_songs_properties_2 = drake_songs.groupby(<COL2>).agg(<AGG2>)
explanation: At some point, filter artist to Drake at some point. Then, show two different properties using two different group by operations.

task: show interesting sub-groups of 5-stars repositories
dataset: github
scheme: Name, Description, URL, Created At, Updated At, Homepage, Size, Stars, Forks, Issues
LDX:
        df = pd.read_csv("github.tsv", delimiter="	")

        5_stars_repos = df[df['Stars'] == '5']

        5_stars_repos_grouped = 5_stars_repos.groupby(<COL1>).agg(<AGG1>)
        5_stars_repos_sub_grouped = 5_stars_repos_grouped.groupby(<COL2>).agg(<AGG2>)
explanation: Filter to repositories with 5 stars.
Then apply some groupby to view it as interesting groups, and apply another groupby to view interesting sub-groups.

now convert the following task to LDX according to the dataset: play_store.tsv and scheme: ['app_id', 'name', 'category', 'rating', 'reviews', 'app_size_kb', 'installs', 'type', 'price', 'content_rating', 'last_updated', 'min_android_ver'], and add explanation.
use this sample of first 5 tuples from the dataset as a reference:
 app_id name                                               category        rating  reviews  app_size_kb  installs type  price content_rating  last_updated  min_android_ver
1           Photo Editor & Candy Camera & Grid & ScrapBook ART_AND_DESIGN 4.1       159    19000           10000  Free 0.0    Everyone       2018          4
2                                      Coloring book moana ART_AND_DESIGN 3.9       967    14000         1000000  Free 0.0    Everyone       2018          4
3       U Launcher Lite â€“ FREE Live Cool Themes, Hide Apps ART_AND_DESIGN 4.7     87510     8700        10000000  Free 0.0    Everyone       2018          4
4                    Pixel Draw - Number Art Coloring Book ART_AND_DESIGN 4.3       967     2800         1000000  Free 0.0    Everyone       2018          4
5                               Paper flowers instructions ART_AND_DESIGN 4.4       167     5600           10000  Free 0.0    Everyone       2017          2

task:
